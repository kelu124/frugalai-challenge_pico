{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text task notebook template\n",
    "## Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[codecarbon WARNING @ 08:42:55] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 08:42:55] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 08:42:55] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 08:42:55] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 08:42:57] CPU Model on constant consumption mode: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 08:42:57] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 08:42:57] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 08:42:57] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 08:42:57]   Platform system: Linux-5.10.230-223.885.amzn2.x86_64-x86_64-with-glibc2.36\n",
      "[codecarbon INFO @ 08:42:57]   Python version: 3.11.11\n",
      "[codecarbon INFO @ 08:42:57]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 08:42:57]   Available RAM : 15.325 GB\n",
      "[codecarbon INFO @ 08:42:57]   CPU count: 4\n",
      "[codecarbon INFO @ 08:42:57]   CPU model: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 08:42:57]   GPU count: 1\n",
      "[codecarbon INFO @ 08:42:57]   GPU model: 1 x Tesla T4\n",
      "[codecarbon INFO @ 08:43:00] Saving emissions data to file /app/notebooks/emissions.csv\n"
     ]
    }
   ],
   "source": [
    "from fastapi import APIRouter\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../tasks')\n",
    "\n",
    "from utils.evaluation import AudioEvaluationRequest\n",
    "from utils.emissions import tracker, clean_emissions_data, get_space_info\n",
    "\n",
    "\n",
    "# Define the label mapping\n",
    "LABEL_MAPPING = {\n",
    "    \"chainsaw\": 0,\n",
    "    \"environment\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmsisdsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 08:43:00.778804: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-30 08:43:00.781470: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-30 08:43:00.785511: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-30 08:43:00.795078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738226580.814136    6130 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738226580.819983    6130 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-30 08:43:00.840160: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cmsisdsp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import pi as PI\n",
    "\n",
    "window_size = 256\n",
    "step_size = 128*8\n",
    "\n",
    "hanning_window_f32 = np.zeros(window_size)\n",
    "for i in range(window_size):\n",
    "  hanning_window_f32[i] = 0.5 * (1 - cmsisdsp.arm_cos_f32(2 * PI * i / window_size ))\n",
    "\n",
    "hanning_window_q15 = cmsisdsp.arm_float_to_q15(hanning_window_f32)\n",
    "\n",
    "rfftq15 = cmsisdsp.arm_rfft_instance_q15()\n",
    "status = cmsisdsp.arm_rfft_init_q15(rfftq15, window_size, 0, 1)\n",
    "\n",
    "def get_arm_spectrogram(waveform):\n",
    "\n",
    "  num_frames = int(1 + (len(waveform) - window_size) // step_size)\n",
    "  fft_size = int(window_size // 2 + 1)\n",
    "  # normalisation du son\n",
    "  waveform = 8*256.0 * (waveform/np.max(np.abs(waveform))-np.mean(waveform))\n",
    "  # Convert the audio to q15\n",
    "  waveform_q15 = cmsisdsp.arm_float_to_q15(waveform)\n",
    "  #print(waveform_q15)\n",
    "  # Create empty spectrogram array\n",
    "  spectrogram_q15 = np.empty((num_frames, fft_size), dtype = np.int16)\n",
    "\n",
    "  start_index = 0\n",
    "\n",
    "  for index in range(num_frames):\n",
    "    # Take the window from the waveform.\n",
    "    window = waveform_q15[start_index:start_index + window_size]\n",
    "\n",
    "    # Apply the Hanning Window.\n",
    "    window = cmsisdsp.arm_mult_q15(window, hanning_window_q15)\n",
    "\n",
    "    # Calculate the FFT, shift by 7 according to docs\n",
    "    window = cmsisdsp.arm_rfft_q15(rfftq15, window)\n",
    "\n",
    "    # Take the absolute value of the FFT and add to the Spectrogram.\n",
    "    spectrogram_q15[index] = cmsisdsp.arm_cmplx_mag_q15(window)[:fft_size]\n",
    "\n",
    "    # Increase the start index of the window by the overlap amount.\n",
    "    start_index += step_size\n",
    "\n",
    "  # Convert to numpy output ready for keras\n",
    "  OUT = cmsisdsp.arm_q15_to_float(spectrogram_q15).reshape(num_frames,fft_size) * 512\n",
    "  AVG = np.average(OUT[0,110:])\n",
    "  MAX = np.max(OUT)\n",
    "\n",
    "  OUT = OUT/ MAX\n",
    "  return tf.reshape(OUT, shape=(35, 129))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.lite as tflite\n",
    "\n",
    "# Load the interpreter and allocate tensors\n",
    "interpreter = tflite.Interpreter( f\"../models/bm_v11.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Load input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "# Set quantization values\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "output_scale, output_zero_point = output_details[\"quantization\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets and splitting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 42\n"
     ]
    }
   ],
   "source": [
    "request = AudioEvaluationRequest()\n",
    "\n",
    "print(request.test_size, request.test_seed)\n",
    "# Load and prepare the dataset\n",
    "dataset = load_dataset(request.dataset_name,cache_dir=\"cache/\")\n",
    "\n",
    "# Split dataset\n",
    "train_test = dataset[\"train\"].train_test_split(test_size=request.test_size, seed=request.test_seed)\n",
    "test_dataset = train_test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1738226585.018929    6130 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "len(test_dataset)\n",
    "\n",
    "for example in test_dataset.select(range(10)):\n",
    "    WAV = example[\"audio\"][\"array\"]\n",
    "    \n",
    "    get_arm_spectrogram(WAV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a generator function for the dataset\n",
    "def dataset_generator(dataset):\n",
    "    for example in dataset:\n",
    "        audio_array = example['audio']['array']\n",
    "        label = example['label']\n",
    "        # Randomly sample 1-5 integers\n",
    "        fold = random.choice([0, 1, 2, 3, 4])\n",
    "        yield audio_array, label, fold\n",
    "\n",
    "def create_arm_spectrogram_for_map(samples, label, fold):\n",
    "    spectrogram = tf.py_function(get_arm_spectrogram, [samples], tf.float32)\n",
    "    return spectrogram, label, fold\n",
    "\n",
    "def remove_fold_column(spectrogram, label, fold):\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1)\n",
    "    spectrogram.set_shape([35, 129, 1])\n",
    "    print(\"The spectrogram Shape\", spectrogram.shape)\n",
    "    return spectrogram, label\n",
    "\n",
    "def filter_by_length(audio, label, path):\n",
    "    return tf.equal(tf.shape(audio)[0], 36000)\n",
    "    \n",
    "def create_testds(DS):\n",
    "    # Convert the dataset to a TensorFlow dataset\n",
    "  test_ds = tf.data.Dataset.from_generator(\n",
    "      lambda: dataset_generator(DS),\n",
    "      output_signature=(\n",
    "          tf.TensorSpec(shape=(None,), dtype=tf.float32),  # Audio array\n",
    "          tf.TensorSpec(shape=(), dtype=tf.int64),         # Label\n",
    "          tf.TensorSpec(shape=(), dtype=tf.int64)         # Path\n",
    "      )\n",
    "  )\n",
    "\n",
    "  \n",
    "  test_ds = test_ds.filter(filter_by_length)\n",
    "  test_ds = test_ds.map(create_arm_spectrogram_for_map)\n",
    "  test_ds = test_ds.map(remove_fold_column)\n",
    "  test_ds = test_ds.cache().batch(32, drop_remainder=True).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "  return test_ds\n",
    "\n",
    "\n",
    "\n",
    "def evalz(test_ds):\n",
    "  results = []\n",
    "  correct = 0\n",
    "  test_ds_len = 0\n",
    "  for x, y in  test_ds.cache().unbatch():\n",
    "      # original tdrishape is [124, 129, 1] expand to [1, 124, 129, 1]\n",
    "      x = tf.expand_dims(x, 0).numpy()\n",
    "      #if not test_ds_len%10:\n",
    "      #  print(test_ds_len)\n",
    "      # quantize the input value\n",
    "      if (input_scale, input_zero_point) != (0, 0):\n",
    "        x = x / input_scale + input_zero_point\n",
    "\n",
    "      X = np.float32(x)\n",
    "      X = X.astype(input_details['dtype'])\n",
    "\n",
    "      try:\n",
    "        # add the input tensor to interpreter\n",
    "        interpreter.set_tensor(input_details[\"index\"], X)\n",
    "\n",
    "        #run the model\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Get output data from model and convert to fp32\n",
    "        output_data = interpreter.get_tensor(output_details[\"index\"])\n",
    "        output_data = output_data.astype(np.float32)\n",
    "\n",
    "        # Dequantize the output\n",
    "        if (output_scale, output_zero_point) != (0.0, 0):\n",
    "          output_data = (output_data - output_zero_point) * output_scale\n",
    "\n",
    "        # convert output to category\n",
    "        if output_data[0][0] >= 0.5:\n",
    "          category = 0\n",
    "        else:\n",
    "          category = 1\n",
    "      except:\n",
    "         category  = random.randint(0, 1)\n",
    "\n",
    "      # add 1 if category = y\n",
    "      correct += 1 if category == y.numpy() else 0\n",
    "      test_ds_len += 1\n",
    "\n",
    "      results.append(category)\n",
    "\n",
    "  return results, correct, test_ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spectrogram Shape (35, 129, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(32, 35, 129, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = train_test[\"test\"]\n",
    "test_ds = create_testds(test_dataset)\n",
    "#test_ds = test_ds.map(create_arm_spectrogram_for_map)\n",
    "test_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_UnbatchDataset element_spec=(TensorSpec(shape=(35, 129, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.take(1).unbatch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracking emissions\n",
    "tracker.start()\n",
    "tracker.start_task(\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 08:44:10.778935: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# YOUR MODEL INFERENCE CODE HERE\n",
    "# Update the code below to replace the random baseline by your model inference within the inference pass where the energy consumption and emissions are tracked.\n",
    "#--------------------------------------------------------------------------------------------   \n",
    "\n",
    "# Make random predictions (placeholder for actual model inference)\n",
    "\n",
    "predictions, correct, test_ds_len = evalz(test_ds)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# YOUR MODEL INFERENCE STOPS HERE\n",
    "#--------------------------------------------------------------------------------------------   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 08:44:10] Energy consumed for RAM : 0.000038 kWh. RAM Power : 5.74672794342041 W\n",
      "[codecarbon INFO @ 08:44:10] Energy consumed for all CPUs : 0.000692 kWh. Total CPU Power : 105.0 W\n",
      "[codecarbon INFO @ 08:44:10] Energy consumed for all GPUs : 0.000092 kWh. Total GPU Power : 13.931956061721136 W\n",
      "[codecarbon INFO @ 08:44:10] 0.000821 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmissionsData(timestamp='2025-01-30T08:44:10', project_name='codecarbon', run_id='91894b0b-b059-41ec-b674-633c1537a041', experiment_id='5b0fa12a-3dd7-45bb-9766-cc326314d9f1', duration=23.716542253000625, emissions=0.0003032031842741412, emissions_rate=1.278461399935696e-05, cpu_power=105.0, gpu_power=13.931956061721136, ram_power=5.74672794342041, cpu_energy=0.0006917466789333464, gpu_energy=9.17864623179998e-05, ram_energy=3.785658139292668e-05, energy_consumed=0.0008213897226442729, country_name='United States', country_iso_code='USA', region='virginia', cloud_provider='', cloud_region='', os='Linux-5.10.230-223.885.amzn2.x86_64-x86_64-with-glibc2.36', python_version='3.11.11', codecarbon_version='2.8.3', cpu_count=4, cpu_model='Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz', gpu_count=1, gpu_model='1 x Tesla T4', longitude=-77.4903, latitude=39.0469, ram_total_size=15.324607849121094, tracking_mode='machine', on_cloud='N', pue=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop tracking emissions\n",
    "emissions_data = tracker.stop_task()\n",
    "emissions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713235294117647"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / test_ds_len\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'submission_timestamp': '2025-01-30T08:44:10.806702',\n",
       " 'accuracy': 0.8713235294117647,\n",
       " 'energy_consumed_wh': 0.8213897226442729,\n",
       " 'emissions_gco2eq': 0.30320318427414117,\n",
       " 'emissions_data': {'run_id': '91894b0b-b059-41ec-b674-633c1537a041',\n",
       "  'duration': 23.716542253000625,\n",
       "  'emissions': 0.0003032031842741412,\n",
       "  'emissions_rate': 1.278461399935696e-05,\n",
       "  'cpu_power': 105.0,\n",
       "  'gpu_power': 13.931956061721136,\n",
       "  'ram_power': 5.74672794342041,\n",
       "  'cpu_energy': 0.0006917466789333464,\n",
       "  'gpu_energy': 9.17864623179998e-05,\n",
       "  'ram_energy': 3.785658139292668e-05,\n",
       "  'energy_consumed': 0.0008213897226442729,\n",
       "  'country_name': 'United States',\n",
       "  'country_iso_code': 'USA',\n",
       "  'region': 'virginia',\n",
       "  'cloud_provider': '',\n",
       "  'cloud_region': '',\n",
       "  'os': 'Linux-5.10.230-223.885.amzn2.x86_64-x86_64-with-glibc2.36',\n",
       "  'python_version': '3.11.11',\n",
       "  'codecarbon_version': '2.8.3',\n",
       "  'cpu_count': 4,\n",
       "  'cpu_model': 'Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz',\n",
       "  'gpu_count': 1,\n",
       "  'gpu_model': '1 x Tesla T4',\n",
       "  'ram_total_size': 15.324607849121094,\n",
       "  'tracking_mode': 'machine',\n",
       "  'on_cloud': 'N',\n",
       "  'pue': 1.0},\n",
       " 'dataset_config': {'dataset_name': 'rfcx/frugalai',\n",
       "  'test_size': 0.2,\n",
       "  'test_seed': 42}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare results dictionary\n",
    "results = {\n",
    "    \"submission_timestamp\": datetime.now().isoformat(),\n",
    "    \"accuracy\": float(accuracy),\n",
    "    \"energy_consumed_wh\": emissions_data.energy_consumed * 1000,\n",
    "    \"emissions_gco2eq\": emissions_data.emissions * 1000,\n",
    "    \"emissions_data\": clean_emissions_data(emissions_data),\n",
    "    \"dataset_config\": {\n",
    "        \"dataset_name\": request.dataset_name,\n",
    "        \"test_size\": request.test_size,\n",
    "        \"test_seed\": request.test_seed\n",
    "    }\n",
    "}\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
